
#ifndef ORIGINAL_H
#define ORIGINAL_H
// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.11.0
// ONNX IR version: 9
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor_Gemm_0_weight[15][7] = 
{
  {1.2861400842666625977f, 0.38754582405090332031f, -0.92005294561386108398f, 0.31939563155174255371f, 0.59305870532989501953f, 0.018378410488367080688f, 0.060337889939546585083f},
  {-0.37296184897422790527f, 0.24039803445339202881f, -0.084135740995407104492f, -0.32061445713043212891f, 0.32610756158828735352f, 0.072345301508903503418f, 0.053360093384981155396f},
  {-0.84569483995437622070f, -0.43063092231750488281f, 0.12618382275104522705f, -0.059384588152170181274f, -0.33787855505943298340f, 1.1557737588882446289f, 0.25765550136566162109f},
  {-0.14369110763072967529f, -0.023794760927557945251f, 0.34389597177505493164f, -0.13305106759071350098f, -0.057867132127285003662f, -0.28281188011169433594f, -0.13037391006946563721f},
  {0.57394713163375854492f, 0.61125493049621582031f, 0.50404292345046997070f, 0.12249088287353515625f, 0.45126524567604064941f, -1.8191902637481689453f, -0.82769864797592163086f},
  {-1.2761620283126831055f, -0.29079428315162658691f, 0.68832874298095703125f, 0.24753239750862121582f, -0.56254398822784423828f, 0.41711774468421936035f, 0.21040032804012298584f},
  {0.80305862426757812500f, 0.49869289994239807129f, -0.68295973539352416992f, 0.42666289210319519043f, -0.11913980543613433838f, 0.77864569425582885742f, 0.61321669816970825195f},
  {-0.30354565382003784180f, 0.36188638210296630859f, -0.18657840788364410400f, 0.37595221400260925293f, -0.24391368031501770020f, -0.17728966474533081055f, -0.32203575968742370605f},
  {-0.049946311861276626587f, 0.25000649690628051758f, -0.31036722660064697266f, -0.23993831872940063477f, -0.16136772930622100830f, -0.21845194697380065918f, 0.067955233156681060791f},
  {-0.23701065778732299805f, -0.031926624476909637451f, -0.21097345650196075439f, -0.16944588720798492432f, -0.11746002733707427979f, -0.053153056651353836060f, -0.34335806965827941895f},
  {-0.52492463588714599609f, -0.10474680364131927490f, -0.068485185503959655762f, 0.00057058321544900536537f, -0.072080880403518676758f, 0.80686229467391967773f, 0.48280110955238342285f},
  {-0.34855255484580993652f, -0.33395573496818542480f, 0.024417491629719734192f, -0.082918748259544372559f, 0.0049635553732514381409f, -0.34881886839866638184f, 0.27528670430183410645f},
  {-0.36862120032310485840f, 0.13943459093570709229f, 0.27070716023445129395f, -0.31568190455436706543f, -0.098145052790641784668f, 0.29810011386871337891f, -0.31393536925315856934f},
  {0.14931753277778625488f, -0.36135378479957580566f, -0.19346931576728820801f, 0.12833085656166076660f, -0.34532666206359863281f, -0.021294780075550079346f, 0.20602017641067504883f},
  {2.1203277111053466797f, 0.31235322356224060059f, -1.2084224224090576172f, 0.44562447071075439453f, 0.99211078882217407227f, -0.28777655959129333496f, 0.67903488874435424805f}
};
static const float tensor_Gemm_0_bias[15] = 
{-0.80081379413604736328f, -0.15213170647621154785f, 0.95242691040039062500f, -0.21969416737556457520f, 0.45055198669433593750f, 0.98627275228500366211f, -0.95152634382247924805f, -0.16031488776206970215f, -0.17894373834133148193f, -0.35233178734779357910f, 0.16883926093578338623f, 0.34132087230682373047f, -0.017851533368229866028f, 0.11587736010551452637f, -1.5915786027908325195f};
static const float tensor_Gemm_1_weight[3][15] = 
{
  {-0.21790593862533569336f, 0.088555462658405303955f, -0.51680237054824829102f, 0.14475181698799133301f, 1.3721135854721069336f, 0.15211233496665954590f, -1.0110138654708862305f, 0.18298603594303131104f, 0.24895432591438293457f, 0.053084619343280792236f, -0.60536730289459228516f, -0.18090489506721496582f, 0.063473261892795562744f, 0.034039985388517379761f, -0.42432522773742675781f},
  {1.4792612791061401367f, 0.25516539812088012695f, -0.80472129583358764648f, -0.091653995215892791748f, -0.45385268330574035645f, -1.0708717107772827148f, 1.1532610654830932617f, 0.064432390034198760986f, 0.068257354199886322021f, -0.023119807243347167969f, -0.19619444012641906738f, -0.050538267940282821655f, 0.18686306476593017578f, -0.22536158561706542969f, 2.2661681175231933594f},
  {-0.96842938661575317383f, -0.24594074487686157227f, 1.3204706907272338867f, 0.13322348892688751221f, -1.3302507400512695312f, 1.4309179782867431641f, -0.37160387635231018066f, -0.040854673832654953003f, -0.035661488771438598633f, 0.17572097480297088623f, 0.68339323997497558594f, -0.17385524511337280273f, -0.18924379348754882812f, 0.17141163349151611328f, -1.9061292409896850586f}
};
static const float tensor_Gemm_1_bias[3] = 
{0.41787940263748168945f, -0.78317952156066894531f, 0.70940554141998291016f};
float tensor_onnx__Gemm_5[1][7];
float tensor_onnx__Gemm_7[1][15];

float tensor_input[1][15];


static inline void node_Flatten_0( const float tensor_onnx__Flatten_0[1][7], float tensor_onnx__Gemm_5[1][7] )
{
	/* Flatten*/
	float *input = (float*)tensor_onnx__Flatten_0;
	float *output = (float*)tensor_onnx__Gemm_5;
	for( uint32_t i=0; i<7; i++ )
		output[i] = input[i];

}

static inline void node_Gemm_1( const float tensor_onnx__Gemm_5[1][7], const float tensor_Gemm_0_weight[15][7], const float tensor_Gemm_0_bias[15], float tensor_input[1][15] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 7;
	const int N = 15;
	float (*A)[7]  = (float(*)[7])tensor_onnx__Gemm_5;
	float (*Y)[15]  = (float(*)[15])tensor_input;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[15]  = (float(*)[15])tensor_Gemm_0_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_0_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node_Relu_2( const float tensor_input[1][15], float tensor_onnx__Gemm_7[1][15] )
{
	/*Relu*/
	float *X = (float*)tensor_input;
	float *Y = (float*)tensor_onnx__Gemm_7;
	for( uint32_t i=0; i<15; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node_Gemm_3( const float tensor_onnx__Gemm_7[1][15], const float tensor_Gemm_1_weight[3][15], const float tensor_Gemm_1_bias[3], float tensor_8[1][3] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 15;
	const int N = 3;
	float (*A)[15]  = (float(*)[15])tensor_onnx__Gemm_7;
	float (*Y)[3]  = (float(*)[3])tensor_8;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[3]  = (float(*)[3])tensor_Gemm_1_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_1_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}


void original(const float tensor_onnx__Flatten_0[1][7], float tensor_8[1][3]) {
	node_Flatten_0( tensor_onnx__Flatten_0, tensor_onnx__Gemm_5);
	node_Gemm_1( tensor_onnx__Gemm_5, tensor_Gemm_0_weight, tensor_Gemm_0_bias, tensor_input);
	node_Relu_2( tensor_input, tensor_onnx__Gemm_7);
	node_Gemm_3( tensor_onnx__Gemm_7, tensor_Gemm_1_weight, tensor_Gemm_1_bias, tensor_8);
}

#endif // ORIGINAL_H

