
#ifndef ORIGINAL_H
#define ORIGINAL_H
// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.11.0
// ONNX IR version: 9
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor_Gemm_0_weight[4][7] = 
{
  {1.6113436222076416016f, 0.49157127737998962402f, -1.1267232894897460938f, 0.42299708724021911621f, 0.66221803426742553711f, 0.71151119470596313477f, 0.30734920501708984375f},
  {-2.4853882789611816406f, -0.25988879799842834473f, 0.55024659633636474609f, -0.40100985765457153320f, -0.90253007411956787109f, 2.0975930690765380859f, 0.57267564535140991211f},
  {0.11976234614849090576f, -0.25272893905639648438f, -0.31019598245620727539f, -0.065280966460704803467f, 0.13848784565925598145f, 0.30185142159461975098f, 0.074104860424995422363f},
  {-0.14369110763072967529f, -0.023794760927557945251f, 0.34389597177505493164f, -0.13305106759071350098f, -0.057867132127285003662f, -0.28281188011169433594f, -0.13037391006946563721f}
};
static const float tensor_Gemm_0_bias[4] = 
{-1.0430865287780761719f, 1.6439692974090576172f, 0.0073994202539324760437f, -0.040628414601087570190f};
static const float tensor_Gemm_1_weight[3][4] = 
{
  {-0.67471408843994140625f, -0.91476631164550781250f, -0.29892426729202270508f, -0.27380108833312988281f},
  {1.7729322910308837891f, -1.7818068265914916992f, 0.43475252389907836914f, -0.15332841873168945312f},
  {-1.4300024509429931641f, 2.9442765712738037109f, 0.025115132331848144531f, 0.49250864982604980469f}
};
static const float tensor_Gemm_1_bias[3] = 
{1.5340750217437744141f, -0.69444698095321655273f, -0.58649140596389770508f};
float tensor_onnx__Gemm_5[1][7];
float tensor_onnx__Gemm_7[1][4];

float tensor_input[1][4];


static inline void node_Flatten_0( const float tensor_onnx__Flatten_0[1][7], float tensor_onnx__Gemm_5[1][7] )
{
	/* Flatten*/
	float *input = (float*)tensor_onnx__Flatten_0;
	float *output = (float*)tensor_onnx__Gemm_5;
	for( uint32_t i=0; i<7; i++ )
		output[i] = input[i];

}

static inline void node_Gemm_1( const float tensor_onnx__Gemm_5[1][7], const float tensor_Gemm_0_weight[4][7], const float tensor_Gemm_0_bias[4], float tensor_input[1][4] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 7;
	const int N = 4;
	float (*A)[7]  = (float(*)[7])tensor_onnx__Gemm_5;
	float (*Y)[4]  = (float(*)[4])tensor_input;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[4]  = (float(*)[4])tensor_Gemm_0_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_0_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node_Relu_2( const float tensor_input[1][4], float tensor_onnx__Gemm_7[1][4] )
{
	/*Relu*/
	float *X = (float*)tensor_input;
	float *Y = (float*)tensor_onnx__Gemm_7;
	for( uint32_t i=0; i<4; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node_Gemm_3( const float tensor_onnx__Gemm_7[1][4], const float tensor_Gemm_1_weight[3][4], const float tensor_Gemm_1_bias[3], float tensor_8[1][3] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 4;
	const int N = 3;
	float (*A)[4]  = (float(*)[4])tensor_onnx__Gemm_7;
	float (*Y)[3]  = (float(*)[3])tensor_8;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[3]  = (float(*)[3])tensor_Gemm_1_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_1_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}


void original(const float tensor_onnx__Flatten_0[1][7], float tensor_8[1][3]) {
	node_Flatten_0( tensor_onnx__Flatten_0, tensor_onnx__Gemm_5);
	node_Gemm_1( tensor_onnx__Gemm_5, tensor_Gemm_0_weight, tensor_Gemm_0_bias, tensor_input);
	node_Relu_2( tensor_input, tensor_onnx__Gemm_7);
	node_Gemm_3( tensor_onnx__Gemm_7, tensor_Gemm_1_weight, tensor_Gemm_1_bias, tensor_8);
}

#endif // ORIGINAL_H

