
#ifndef ORIGINAL_H
#define ORIGINAL_H
// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.11.0
// ONNX IR version: 9
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

static const float tensor_Gemm_0_weight[6][7] = 
{
  {2.1053760051727294922f, 0.69817602634429931641f, -0.92195278406143188477f, 0.48756787180900573730f, 1.1743717193603515625f, -0.71086704730987548828f, -0.091800741851329803467f},
  {-2.0758521556854248047f, -0.062751315534114837646f, 0.96405547857284545898f, -0.36658418178558349609f, -0.28188547492027282715f, 0.24365140497684478760f, -0.15242189168930053711f},
  {0.11839124560356140137f, -0.25448206067085266113f, -0.31234949827194213867f, -0.067022152245044708252f, 0.13672806322574615479f, 0.29964977502822875977f, 0.072391957044601440430f},
  {0.82943302392959594727f, 0.29122877120971679688f, 0.25029757618904113770f, -0.0045065633021295070648f, 0.59987735748291015625f, -1.5381885766983032227f, -0.35392269492149353027f},
  {0.041006892919540405273f, 0.29901149868965148926f, 0.0073994202539324760437f, -0.040628414601087570190f, -0.26802110671997070312f, -0.33995357155799865723f, -0.22596549987792968750f},
  {-1.1682978868484497070f, -0.31464394927024841309f, 0.45583710074424743652f, 0.21912792325019836426f, -0.63020730018615722656f, 0.65571522712707519531f, 0.37756043672561645508f}
};
static const float tensor_Gemm_0_bias[6] = 
{-1.1304461956024169922f, 1.7749397754669189453f, 0.020974723622202873230f, -0.040834818035364151001f, -0.20914775133132934570f, 0.86553812026977539062f};
static const float tensor_Gemm_1_weight[3][6] = 
{
  {-0.0012333544436842203140f, -0.040028166025876998901f, 0.39080014824867248535f, 1.0267034769058227539f, 0.40607485175132751465f, -0.65631043910980224609f},
  {1.8546645641326904297f, -2.3260691165924072266f, -0.054019756615161895752f, 0.16065806150436401367f, -0.33523491024971008301f, -1.1661547422409057617f},
  {-2.1530587673187255859f, 1.4544359445571899414f, 0.073553480207920074463f, -1.3748513460159301758f, -0.034484699368476867676f, 1.0719685554504394531f}
};
static const float tensor_Gemm_1_bias[3] = 
{-0.15346047282218933105f, -0.71367174386978149414f, 0.49982962012290954590f};
float tensor_onnx__Gemm_5[1][7];
float tensor_onnx__Gemm_7[1][6];

float tensor_input[1][6];


static inline void node_Flatten_0( const float tensor_onnx__Flatten_0[1][7], float tensor_onnx__Gemm_5[1][7] )
{
	/* Flatten*/
	float *input = (float*)tensor_onnx__Flatten_0;
	float *output = (float*)tensor_onnx__Gemm_5;
	for( uint32_t i=0; i<7; i++ )
		output[i] = input[i];

}

static inline void node_Gemm_1( const float tensor_onnx__Gemm_5[1][7], const float tensor_Gemm_0_weight[6][7], const float tensor_Gemm_0_bias[6], float tensor_input[1][6] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 7;
	const int N = 6;
	float (*A)[7]  = (float(*)[7])tensor_onnx__Gemm_5;
	float (*Y)[6]  = (float(*)[6])tensor_input;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[6]  = (float(*)[6])tensor_Gemm_0_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_0_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}

static inline void node_Relu_2( const float tensor_input[1][6], float tensor_onnx__Gemm_7[1][6] )
{
	/*Relu*/
	float *X = (float*)tensor_input;
	float *Y = (float*)tensor_onnx__Gemm_7;
	for( uint32_t i=0; i<6; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;

}

static inline void node_Gemm_3( const float tensor_onnx__Gemm_7[1][6], const float tensor_Gemm_1_weight[3][6], const float tensor_Gemm_1_bias[3], float tensor_8[1][3] )
{
	/* Gemm */
	/* alpha   = 1.0000000000000000000
	   beta    = 1.0000000000000000000
	   transA  = 0
	   transB  = 1
	 */
	const int M = 1;
	const int K = 6;
	const int N = 3;
	float (*A)[6]  = (float(*)[6])tensor_onnx__Gemm_7;
	float (*Y)[3]  = (float(*)[3])tensor_8;
	float alpha = 1.0000000000000000000;
	float beta = 1.0000000000000000000;
	float (*C)[3]  = (float(*)[3])tensor_Gemm_1_bias;
	for( uint32_t r=0; r<M; r++ )
		for( uint32_t c=0; c<N; c++ ) {
			float ABrc = 0;
			for( uint32_t i=0; i<K; i++ ) {
				float B = tensor_Gemm_1_weight[c][i];
				ABrc += A[r][i] * B;
			}
			float tmp = ABrc * alpha;
			tmp += C[0][c] * beta;
			Y[r][c] = tmp;
	}
}


void original(const float tensor_onnx__Flatten_0[1][7], float tensor_8[1][3]) {
	node_Flatten_0( tensor_onnx__Flatten_0, tensor_onnx__Gemm_5);
	node_Gemm_1( tensor_onnx__Gemm_5, tensor_Gemm_0_weight, tensor_Gemm_0_bias, tensor_input);
	node_Relu_2( tensor_input, tensor_onnx__Gemm_7);
	node_Gemm_3( tensor_onnx__Gemm_7, tensor_Gemm_1_weight, tensor_Gemm_1_bias, tensor_8);
}

#endif // ORIGINAL_H

